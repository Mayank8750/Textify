{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Project .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop_Words\n",
    "stop_words = {'a','about','above','after','again','against','ain','all','am','an','and','any','are','aren',\"aren't\",'as','at','be','because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves'}\n",
    "# Common_Words(common for most of documents(not of any use)) ..\n",
    "Common_words = ['->' ,'subject:', '**' , '/*' ,'1.1' , '28' , '0' , 'newsgroups', 'xref', 'path', 'from', 'subject', 'sender', 'organisation', 'apr','gmt', 'last','better','never','every','even','two','good','used','first','need','going','must','really','might','well','without','made','give','look','try','far','less','seem','new','make','many','way','since','using','take','help','thanks','send','free','may','see','much','want','find','would','one','like','get','use','also','could','say','us','go','please','said','set','got','sure','come','lot','seems','able','anything','put', '--', '|>', '>>', '93', 'xref', 'cantaloupe.srv.cs.cmu.edu', '20', '16', \"max>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'\", '21', '19', '10', '17', '24', 'reply-to:', 'thu', 'nntp-posting-host:', 're:','25''18'\"i'd\"'>i''22''fri,''23''>the','references:','xref:','sender:','writes:','1993','organization:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "punctuations = list(string.punctuation)\n",
    "stop_words.update(punctuations)\n",
    "stop_words.update(Common_words)\n",
    "# Now stop words contains all unnecessary/irrelvent words\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NewsGroup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-97e3bd64e445>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# '/20_newsgroups' file is present in my pc (downloads)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mNewsGroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'downloads./20_newsgroups'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNewsGroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NewsGroup' is not defined"
     ]
    }
   ],
   "source": [
    "# '/20_newsgroups' file is present in my pc (downloads)\n",
    "NewsGroup\n",
    "s = [f for f in os.listdir('downloads./20_newsgroups')]\n",
    "len(NewsGroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocab :- Builds vocablury(dictionary) of words (as keys) with frequencies (as values) .\n",
    "def Vocab(newsgroups):\n",
    "    dic = {}\n",
    "    for newsgrp in newsgroups:\n",
    "        f_num = os.listdir('downloads./20_newsgroups/' + newsgrp)\n",
    "        total_f = len(f_num)\n",
    "        for i in range (total_f):\n",
    "            txt_file = open('downloads./20_newsgroups/' + newsgrp + '/' + f_num[i] , 'r').read()\n",
    "            for txt in txt_file.split():\n",
    "                if txt.lower() not in stop_words:\n",
    "                    if txt.lower() in dic:\n",
    "                        dic[txt.lower()] += 1\n",
    "                    else:\n",
    "                          dic[txt.lower()] = 1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425260"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = Vocab(NewsGroups)\n",
    "len(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting dictionary in descending order of frequencies => To get top features ..\n",
    "features = sorted(dic , key = dic.__getitem__ , reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting top 1000 words from dictionary as features ..\n",
    "top_features = features[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from:',\n",
       " 'date:',\n",
       " 'newsgroups:',\n",
       " 'message-id:',\n",
       " 'lines:',\n",
       " 'path:',\n",
       " 'article',\n",
       " 'people',\n",
       " 'university',\n",
       " 'know',\n",
       " 'think',\n",
       " 'x',\n",
       " \"i'm\",\n",
       " '1',\n",
       " '2',\n",
       " 'distribution:',\n",
       " 'time',\n",
       " 'it.',\n",
       " 'anyone',\n",
       " 'world',\n",
       " 'right',\n",
       " 'believe',\n",
       " 'still',\n",
       " 'something',\n",
       " 'computer',\n",
       " 'system',\n",
       " \"i've\",\n",
       " 'god',\n",
       " '15',\n",
       " '3',\n",
       " 'back',\n",
       " \"can't\",\n",
       " 'news',\n",
       " 'state',\n",
       " '6',\n",
       " 'work',\n",
       " 'someone',\n",
       " '>in',\n",
       " '5',\n",
       " 'government',\n",
       " 'problem',\n",
       " '23',\n",
       " 'another',\n",
       " 'read',\n",
       " 'usa',\n",
       " '4',\n",
       " 'information',\n",
       " '>the',\n",
       " 'number',\n",
       " \"that's\",\n",
       " 'things',\n",
       " 'part',\n",
       " 'fri,',\n",
       " 'point',\n",
       " 'little',\n",
       " '22',\n",
       " 'windows',\n",
       " '>i',\n",
       " 'tue,',\n",
       " 'file',\n",
       " 'data',\n",
       " 'question',\n",
       " 'probably',\n",
       " 'years',\n",
       " 'different',\n",
       " 'available',\n",
       " '(usenet',\n",
       " 'space',\n",
       " 'it,',\n",
       " 'around',\n",
       " 'long',\n",
       " 'tell',\n",
       " 'least',\n",
       " 'best',\n",
       " 'program',\n",
       " 'software',\n",
       " 'public',\n",
       " 'power',\n",
       " 'thu,',\n",
       " 'thing',\n",
       " 'drive',\n",
       " 'run',\n",
       " 'support',\n",
       " 'however,',\n",
       " \"i'd\",\n",
       " '18',\n",
       " 'rather',\n",
       " 'enough',\n",
       " 'case',\n",
       " 'hard',\n",
       " 'keep',\n",
       " 'fact',\n",
       " '25',\n",
       " 'let',\n",
       " 'science',\n",
       " 'called',\n",
       " 'great',\n",
       " '...',\n",
       " 'call',\n",
       " 'looking']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NewsGroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to DataFrame(df)\n",
    "df = pd.DataFrame(columns = top_features)\n",
    "for newsgrp in NewsGroups:\n",
    "    f_num = os.listdir('downloads./20_newsgroups/' + newsgrp)\n",
    "    for i in range(len(f_num)):\n",
    "        txt_file = open('downloads./20_newsgroups/' + newsgrp + '/' + f_num[i] , 'r').read()\n",
    "        df.loc[len(df)] = np.zeros(len(top_features))\n",
    "        for wrd in txt_file.split():\n",
    "            if wrd in top_features:\n",
    "                df[wrd.lower()][len(df) - 1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining Y (output) :- classes  \n",
    "def Y_Data(NewsGroups):\n",
    "    Y = []\n",
    "    for news_grp in NewsGroups: \n",
    "        f_num = os.listdir('./20_newsgroups/' + news_grp)\n",
    "        for i in range(len(f_num)):\n",
    "            Y.append(news_grp)\n",
    "    Y = np.array(Y)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y_Data(NewsGroups)\n",
    "classes = set(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INBUILT IMPLEMENTATION (MULTINOMIAL NAIVE BAYES) .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Inbuilt Multinomial Naive Bayes \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "x_train , x_test , y_train , y_test = train_test_split(X , Y)           #Splitting data to train test ..\n",
    "clf = MNB()                                                             # Multinomial Naive Bayes classifier object(clf) ..\n",
    "clf.fit(x_train, y_train)                                               #Fitting Data to multinomial Naive Bayes Classifier ..\n",
    "y_pred = clf.predict(x_test)    \n",
    "test_score = clf.score(x_test, y_test)                                  # Calculating Scores for inbuilt classifier ..\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names = list(df)          #List Of Selected Features .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELF-IMPLEMENTATION (MULTINOMIAL NAIVE BAYES) .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit :- As to fit the training data (x_train , y_train) to an algorithm (storing the req values in result dictionary), result later used for calculating y_pred(in predict function) ..\n",
    "def fit(X_train, Y_train):\n",
    "    result = {}\n",
    "    class_values = set(Y_train)\n",
    "    for current_class in class_values:\n",
    "        result[current_class] = {}\n",
    "        result[\"total_data\"] = len(Y_train)\n",
    "        current_class_rows = (Y_train == current_class)\n",
    "        X_train_current = X_train[current_class_rows]\n",
    "        Y_train_current = Y_train[current_class_rows]\n",
    "        denominator = 0\n",
    "        result[current_class][\"total_count\"] = 0\n",
    "        num_features = len(features_names)\n",
    "        for j in range(num_features):\n",
    "            result[current_class][features_names[j]] = X_train_current[ : , j].sum()\n",
    "            denominator += result[current_class][features_names[j]]\n",
    "        result[current_class][\"total_count\"] = denominator       \n",
    "    return result        # returning dictionary containing various counts for training data that are later used for prediciton .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability :- To calculate log probablity(Comparison Value){Not Actually Probablity (just estimate)} for given set of values for features of x ..\n",
    "def probability(dictionary, x, current_class):\n",
    "    output = np.log(dictionary[current_class][\"total_count\"]) - np.log(dictionary[\"total_data\"])\n",
    "    num_features = len(features_names);\n",
    "    for j in range(1, num_features + 1):\n",
    "        xj = x[j - 1]\n",
    "        count_current_class_with_value_xj = dictionary[current_class][features_names[j-1]] + 1\n",
    "        count_current_class = dictionary[current_class][\"total_count\"] + len(features_names)\n",
    "        current_xj_probablity = np.log(count_current_class_with_value_xj) - np.log(count_current_class)\n",
    "        output = output + xj*current_xj_probablity\n",
    "    return output                    # returning a comparison value (not the actual probablity) .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PredictSinglePoint :- function to predict y(best class) for a single value of x_test ..\n",
    "def predictSinglePoint(dictionary, x):\n",
    "    classes = dictionary.keys()\n",
    "    best_p = -1000\n",
    "    best_class = -1\n",
    "    first_run = True\n",
    "    for current_class in classes:\n",
    "        if (current_class == \"total_data\"):\n",
    "            continue\n",
    "        p_current_class = probability(dictionary, x, current_class)\n",
    "        if (first_run or p_current_class > best_p):\n",
    "            best_p = p_current_class\n",
    "            best_class = current_class\n",
    "        first_run = False\n",
    "    return best_class                # Returning best class(y_pred) for a given set of features for single x_test .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Function :- To predict y for given set of values of x_test\n",
    "def predict(dictionary, X_test):\n",
    "    y_pred = []\n",
    "    for i in range(len(X_test)):\n",
    "        x_class = predictSinglePoint(dictionary, X_test[i , :])\n",
    "        y_pred.append(x_class)\n",
    "    return y_pred              # Returning y_pred tuple .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting The train data ..\n",
    "clf1 = fit(x_train, y_train)    # clf :- dictionary containing various counts of training data(used for estimating class for testing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling predict to get y_pred for given x_test ..\n",
    "y_pred1 = predict(clf1 , x_test)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Accuracy_Score (From sklearn.metrics) To Compare Y_true & Y_pred ..\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inbuilt_Score = test_score\n",
    "Self_Made_MNB_Score = accuracy_score(y_test, y_pred)\n",
    "Inbuilt_Score , Self_Made_MNB_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix ..\n",
    "from sklearn.metrics import confusion_matrix\n",
    "Inbuilt_Confusion_Matrix = confusion_matrix(y_pred , y_test)\n",
    "Self_Made_CLF_Confusion_Matrix = confusion_matrix(y_pred1 , y_test)\n",
    "Inbuilt_Confusion_Matrix , Self_Made_CLF_Confusion_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inbuilt classifier ..\n",
    "print(classification_report(y_test ,y_pred , target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For self made classifier ..\n",
    "print(classification_report(y_test ,y_pred1 , target_names=classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
